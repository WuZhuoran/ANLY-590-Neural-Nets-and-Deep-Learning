{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1329,
     "status": "ok",
     "timestamp": 1541811929334,
     "user": {
      "displayName": "Keegan Hines",
      "photoUrl": "",
      "userId": "14251275254080316358"
     },
     "user_tz": 300
    },
    "id": "XOkBF0K6P6MC",
    "outputId": "28491ef6-b752-4f09-a797-6d7a4af022ed"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, SimpleRNN, LSTM\n",
    "from keras.preprocessing.text import Tokenizer, one_hot\n",
    "from keras.optimizers import RMSprop\n",
    "# from google.colab import drive\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 27779,
     "status": "ok",
     "timestamp": 1541811957994,
     "user": {
      "displayName": "Keegan Hines",
      "photoUrl": "",
      "userId": "14251275254080316358"
     },
     "user_tz": 300
    },
    "id": "dX7qrncTRKN0",
    "outputId": "c3de5591-d3d1-44c6-b2eb-6c44d603a7b6"
   },
   "outputs": [],
   "source": [
    "# drive.mount('/content/gdrive/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6iek9QSARq1L"
   },
   "outputs": [],
   "source": [
    "file_path = \"shakespeare.txt\"\n",
    "\n",
    "with open(file_path,\"r\") as f:\n",
    "  text = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ie2LtLF4Vv6A"
   },
   "source": [
    "We've loaded our Shakespeare text, let's take a look at a random snippet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 196,
     "status": "ok",
     "timestamp": 1541815312567,
     "user": {
      "displayName": "Keegan Hines",
      "photoUrl": "",
      "userId": "14251275254080316358"
     },
     "user_tz": 300
    },
    "id": "LVFmTUsGWePe",
    "outputId": "293906af-e47c-4f89-9856-283707adc1df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",\n",
      "  Which though it alter not love's sole effect,\n",
      "  Yet doth it steal sweet hours from love's delight.\n",
      "  I may not evermore acknowledge thee,\n",
      "  Lest my bewailed guilt should do thee shame,\n",
      "  Nor thou with public kindness honour me,\n",
      "  Unless thou take that honour from thy name:\n",
      "    But do not so, I love thee in such sort,\n",
      "    As thou being mine, mine is thy good report.\n",
      "\n",
      "\n",
      "                     37\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "print(text[31600:32000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qLXQHFUsW0xu"
   },
   "source": [
    "We need to convert our text into numeric arrays, the next several blocks accomplish this.\n",
    "\n",
    "First, we'll create a mapping between characters and their numeric index. We'll also create the reverse mapping, which is useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 198,
     "status": "ok",
     "timestamp": 1541811961995,
     "user": {
      "displayName": "Keegan Hines",
      "photoUrl": "",
      "userId": "14251275254080316358"
     },
     "user_tz": 300
    },
    "id": "UkvcQEUASXQG",
    "outputId": "6ba5f988-e63c-4386-c9cc-147f610bd50e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 93\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "print('total chars:', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XexyPZdAXC0p"
   },
   "source": [
    "Next, we'll create a training set of sub-sequences. Remember, we're trying to train a model to be able to predict the next chracter if it is given several characters of a subsequence. So we will create training pairs where each X is a fixed-length subsequences and each Y is the corresponding next letter in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 210,
     "status": "ok",
     "timestamp": 1541811964049,
     "user": {
      "displayName": "Keegan Hines",
      "photoUrl": "",
      "userId": "14251275254080316358"
     },
     "user_tz": 300
    },
    "id": "ej4RdC76S7RB",
    "outputId": "079d2df8-595a-41ff-c231-09336440dc0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences: 1821785\n"
     ]
    }
   ],
   "source": [
    "maxlen = 40\n",
    "step = 3\n",
    "sub_sequences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sub_sequences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('nb sequences:', len(sub_sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 181,
     "status": "ok",
     "timestamp": 1541815609053,
     "user": {
      "displayName": "Keegan Hines",
      "photoUrl": "",
      "userId": "14251275254080316358"
     },
     "user_tz": 300
    },
    "id": "QVHru3qPWX8Z",
    "outputId": "69e331cb-7aa9-4cef-8a4d-e4deef23e188"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Sequence):\n",
      "ration with World Library, Inc., from th\n",
      "\n",
      "(Target Character): \n",
      "e\n"
     ]
    }
   ],
   "source": [
    "k=300\n",
    "print(\"(Sequence):\\n\" + sub_sequences[k])\n",
    "print(\"\\n(Target Character): \\n\" + next_chars[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vD2QxlOAW8zQ"
   },
   "source": [
    "Next we'll create one-hot vectors for our sub-sequences. The tensor we create here will be shaped as (batch_size x seq_length x vocab_size)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SfQRBmiNWehk"
   },
   "outputs": [],
   "source": [
    "X = np.zeros((len(sub_sequences), maxlen, len(chars)), dtype=np.uint8 )\n",
    "Y = np.zeros((len(sub_sequences), len(chars)), dtype=np.uint8)\n",
    "for i, seq in enumerate(sub_sequences):\n",
    "    for t, char in enumerate(seq):\n",
    "        X[i, t, char_indices[char]] = 1\n",
    "        Y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 208,
     "status": "ok",
     "timestamp": 1541811974706,
     "user": {
      "displayName": "Keegan Hines",
      "photoUrl": "",
      "userId": "14251275254080316358"
     },
     "user_tz": 300
    },
    "id": "U4qxjsGDXLtb",
    "outputId": "6987b113-41af-411d-bd5f-8f1e62fe467b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 1, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1222,
     "status": "ok",
     "timestamp": 1541731857371,
     "user": {
      "displayName": "Keegan Hines",
      "photoUrl": "",
      "userId": "14251275254080316358"
     },
     "user_tz": 300
    },
    "id": "423pgyKqXnE_",
    "outputId": "38e5fd04-3637-4463-ab2d-55ffb340830a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0], dtype=uint8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2dJrr1caYVnI"
   },
   "source": [
    "Our RNN model will be quite simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "95NSRVMpYGAT"
   },
   "outputs": [],
   "source": [
    "char_rnn = Sequential()\n",
    "char_rnn.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "char_rnn.add(Dense(len(chars),activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t4xdUMP_Y6iu"
   },
   "outputs": [],
   "source": [
    "\n",
    "char_rnn.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 382
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 89342,
     "status": "ok",
     "timestamp": 1541813397192,
     "user": {
      "displayName": "Keegan Hines",
      "photoUrl": "",
      "userId": "14251275254080316358"
     },
     "user_tz": 300
    },
    "id": "KGDTEd0GZFNk",
    "outputId": "150ec6d5-66cd-4a8e-cb15-3ef863ea04d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1821785/1821785 [==============================] - 856s 470us/step - loss: 1.4361\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1cf8d3cbc88>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_rnn.fit(X,Y, epochs=1, batch_size=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6hhAWPgRX96V"
   },
   "source": [
    "Once we have a trained model, we can simulate new text by making predictions about the next character and then drawing characters in proportion to the predicted probabilities. And then simple repeat that process over and over, each time drawing the next character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IMpJwYSsZSoc"
   },
   "outputs": [],
   "source": [
    "def draw_char(probs):\n",
    "    probs = np.asarray(probs).astype('float64')\n",
    "    if sum(probs) != 1.0:\n",
    "      probs = probs / np.sum(probs)\n",
    "    draw = np.random.choice(range(len(probs)) , p=probs)\n",
    "    return draw\n",
    "\n",
    "def sample_text(model, sample_length=100):\n",
    "    start = np.random.randint(0, len(text) - maxlen - 1)\n",
    "    sequence = text[start: start + maxlen]\n",
    "  \n",
    "    x_preds = np.zeros((sample_length, maxlen, len(chars)))\n",
    "    for i in range(sample_length):\n",
    "        for t, char in enumerate(sequence[-maxlen:]):\n",
    "            x_preds[i, t, char_indices[char]] = 1.\n",
    "\n",
    "        preds = model.predict(np.expand_dims(x_preds[i,:,:], axis=0), verbose=0)[0]\n",
    "        next_index = draw_char(preds)\n",
    "        next_char = indices_char[next_index]\n",
    "\n",
    "        sequence += next_char\n",
    "    return sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jHD5iDlHayL7"
   },
   "outputs": [],
   "source": [
    "sim = sample_text(char_rnn,sample_length=500) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 191,
     "status": "ok",
     "timestamp": 1541814414433,
     "user": {
      "displayName": "Keegan Hines",
      "photoUrl": "",
      "userId": "14251275254080316358"
     },
     "user_tz": 300
    },
    "id": "bOP0ljRtOEmp",
    "outputId": "9f545999-a610-4d7a-f7c4-aa07fc320b10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ariadne and Antiopa?\n",
      "  TITANIA. These arraning; whil the come in country'd upsorn'd him of Graf's tenradie,\n",
      "    Subshion to mecom to no way's suctanies\n",
      "    If then then no Nerdent to away those denchy\n",
      "  and go.\n",
      "  MAYMERSIE. And breaks hath curben'd, was but sun, while,\n",
      "      By happy by womb?\n",
      "  PROTEU. Leg how fathers consently,\n",
      "    My save hath a goldhing theseived,\n",
      "    Ay; and he way, and to tidon'd breeding on.\n",
      "  GOSTRIDABURY. My brothers be discommardly and knight,\n",
      "    Our 'twaef ourselves attend so that in wally?\n",
      "  Beding. My ver\n"
     ]
    }
   ],
   "source": [
    "print(sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Aj4kXg4BTbOc"
   },
   "source": [
    "Notice that we can do pretty well to learn the typical statistical patterns of this text and then simulate new text that appears to be very similar to legitimate Shakespeare. \n",
    "\n",
    "But just a caution - we can also do pretty well with a much simpler method (Markov model): http://nbviewer.jupyter.org/gist/yoavg/d76121dfde2618422139\n",
    "\n",
    "So the lesson is to try something simple before jumping right in to deep learning."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CharRNN.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
