{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Honor Statement\n",
    "\n",
    "Name: Zhuoran Wu\n",
    "\n",
    "E-mail: <zw118@georgetown.edu>\n",
    "\n",
    "Platform: Windows\n",
    "\n",
    "In accordance with the class policies and Georgetown's Honor Code,\n",
    "I certify that, with the exceptions of the class resources and those\n",
    "items noted below, I have neither given nor received any assistance\n",
    "on this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Autoencoder\n",
    "\n",
    "A convolutional autoencoder is a particular flavor of autoencoder where we use convolutional layers instead of dense layers. We have previously applied autoencoders to images using only Dense layers and the result worked fairly well. However, the local spatial correlations of images imply that we should be able to do better using convolutional layers instead of Dense layers.\n",
    "\n",
    "Build and fit a convolutional autoencoder for the Fashion MNIST dataset. The components of this network will be many of the same pieces we've used with convolutional classification networks: Conv2D, MaxPooling, and so on. The encoder part of the network should run the input image through a few convolutional layers of your choice. The decoder part of the network will utilize UpSampling2D to get the representation back to the original image size.\n",
    "\n",
    "An example to guide your thinking can be found toward the bottom of this\n",
    "post https://blog.keras.io/building-autoencoders-in-keras.html.\n",
    "\n",
    "After training your network, visualize some examples of input images and\n",
    "their decoded reconstruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Image Classification\n",
    "\n",
    "We'll continue to use the Fashion MNIST dataset and build a deep convolutional\n",
    "network for classification.\n",
    "\n",
    "## 2.1 Deep CNN\n",
    "\n",
    "Build a deep CNN to classify the images. Provide a brief description of the\n",
    "architectural choices you've made: kernel sizes, strides, padding, network depth.\n",
    "Train your network end-to-end. Report on your model's performance on training\n",
    "set and test set.\n",
    "\n",
    "## 2.2 Transfer Learning\n",
    "\n",
    "Repeat the same task, but this time utilize a pre-trained network for the major-\n",
    "ity of your model. You should only train the final Dense layer, all other weights should be fixed. You can use whichever pre-trained backbone you like (ResNet,VGG, etc). Report on your model's performance on training set and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Text Classification\n",
    "\n",
    "While images contain local spatial correlations and structure, many other datasets\n",
    "contain temporal correlations. Examples include time series and discrete se-\n",
    "quences such as text. In this problem, we will tackle the task of text classifica-\n",
    "tion in the context of cybersecurity.\n",
    "\n",
    "**Background.** When malware infects a host computer, it often needs to\n",
    "reach out to an outside server for further instructions or to download additional\n",
    "payloads. This outside server is called a Command-and-Control server (C2).\n",
    "The malware needs to send a specific communication to the C2 server, thus the\n",
    "C2 server needs to have a registered IP address or associated web domain so\n",
    "that it can be reached. Therefore, being able to identify web domains that are\n",
    "likely related to malware C2 can be a valuable cyber defense.\n",
    "\n",
    "**Dataset.** Fortunately, security researchers have already identified and logged\n",
    "a large number of malicious URLs. Additionally, we can catalog common \"be-\n",
    "nign\" URLs just from typical web behavior (these would include things like\n",
    "facebook.com and amazon.com). Hence, we have a labeled dataset for text\n",
    "classification which can be downloaded here:\n",
    "\n",
    "* https://s3.amazonaws.com/anly-590/url-classification/benign-urls.txt\n",
    "\n",
    "* https://s3.amazonaws.com/anly-590/url-classification/malicious-urls.txt\n",
    "\n",
    "\n",
    "## 3.1 RNN\n",
    "\n",
    "Build and train a Recurrent Neural Network to solve this text classification task.\n",
    "You can use any type of RNN you wish (SimpleRNN, GRU, LSTM).\n",
    "\n",
    "## 3.2 CNN\n",
    "\n",
    "Build and train a 1D CNN for this text classification task. You might gain some\n",
    "insight and inspiration from these text classification approaches:\n",
    "\n",
    "* http://www.aclweb.org/anthology/D14-1181\n",
    "\n",
    "* https://arxiv.org/abs/1702.08568\n",
    "\n",
    "## 3.3\n",
    "\n",
    "Be sure to directly compare your two methods with an ROC curve or similar\n",
    "validation method. Don't forget to create a train-test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Classification"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
